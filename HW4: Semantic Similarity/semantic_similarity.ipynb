{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1a81375",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from nltk.corpus import wordnet as wn\n",
    "import fasttext.util\n",
    "from scipy.spatial.distance import cosine\n",
    "from scipy.stats import kendalltau\n",
    "from gensim.models import KeyedVectors   # for loading .vec format files\n",
    "\n",
    "import io\n",
    "import gc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63708c4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word1</th>\n",
       "      <th>word2</th>\n",
       "      <th>POS</th>\n",
       "      <th>SimLex999</th>\n",
       "      <th>conc(w1)</th>\n",
       "      <th>conc(w2)</th>\n",
       "      <th>concQ</th>\n",
       "      <th>Assoc(USF)</th>\n",
       "      <th>SimAssoc333</th>\n",
       "      <th>SD(SimLex)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>old</td>\n",
       "      <td>new</td>\n",
       "      <td>A</td>\n",
       "      <td>1.58</td>\n",
       "      <td>2.72</td>\n",
       "      <td>2.81</td>\n",
       "      <td>2</td>\n",
       "      <td>7.25</td>\n",
       "      <td>1</td>\n",
       "      <td>0.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>smart</td>\n",
       "      <td>intelligent</td>\n",
       "      <td>A</td>\n",
       "      <td>9.20</td>\n",
       "      <td>1.75</td>\n",
       "      <td>2.46</td>\n",
       "      <td>1</td>\n",
       "      <td>7.11</td>\n",
       "      <td>1</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hard</td>\n",
       "      <td>difficult</td>\n",
       "      <td>A</td>\n",
       "      <td>8.77</td>\n",
       "      <td>3.76</td>\n",
       "      <td>2.21</td>\n",
       "      <td>2</td>\n",
       "      <td>5.94</td>\n",
       "      <td>1</td>\n",
       "      <td>1.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>happy</td>\n",
       "      <td>cheerful</td>\n",
       "      <td>A</td>\n",
       "      <td>9.55</td>\n",
       "      <td>2.56</td>\n",
       "      <td>2.34</td>\n",
       "      <td>1</td>\n",
       "      <td>5.85</td>\n",
       "      <td>1</td>\n",
       "      <td>2.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hard</td>\n",
       "      <td>easy</td>\n",
       "      <td>A</td>\n",
       "      <td>0.95</td>\n",
       "      <td>3.76</td>\n",
       "      <td>2.07</td>\n",
       "      <td>2</td>\n",
       "      <td>5.82</td>\n",
       "      <td>1</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>join</td>\n",
       "      <td>acquire</td>\n",
       "      <td>V</td>\n",
       "      <td>2.85</td>\n",
       "      <td>2.86</td>\n",
       "      <td>2.93</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>send</td>\n",
       "      <td>attend</td>\n",
       "      <td>V</td>\n",
       "      <td>1.67</td>\n",
       "      <td>2.70</td>\n",
       "      <td>3.17</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>gather</td>\n",
       "      <td>attend</td>\n",
       "      <td>V</td>\n",
       "      <td>4.80</td>\n",
       "      <td>2.75</td>\n",
       "      <td>3.17</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>absorb</td>\n",
       "      <td>withdraw</td>\n",
       "      <td>V</td>\n",
       "      <td>2.97</td>\n",
       "      <td>3.11</td>\n",
       "      <td>3.04</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>attend</td>\n",
       "      <td>arrive</td>\n",
       "      <td>V</td>\n",
       "      <td>6.08</td>\n",
       "      <td>3.17</td>\n",
       "      <td>3.22</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1.18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>999 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      word1        word2 POS  SimLex999  conc(w1)  conc(w2)  concQ  \\\n",
       "0       old          new   A       1.58      2.72      2.81      2   \n",
       "1     smart  intelligent   A       9.20      1.75      2.46      1   \n",
       "2      hard    difficult   A       8.77      3.76      2.21      2   \n",
       "3     happy     cheerful   A       9.55      2.56      2.34      1   \n",
       "4      hard         easy   A       0.95      3.76      2.07      2   \n",
       "..      ...          ...  ..        ...       ...       ...    ...   \n",
       "994    join      acquire   V       2.85      2.86      2.93      2   \n",
       "995    send       attend   V       1.67      2.70      3.17      2   \n",
       "996  gather       attend   V       4.80      2.75      3.17      2   \n",
       "997  absorb     withdraw   V       2.97      3.11      3.04      2   \n",
       "998  attend       arrive   V       6.08      3.17      3.22      2   \n",
       "\n",
       "     Assoc(USF)  SimAssoc333  SD(SimLex)  \n",
       "0          7.25            1        0.41  \n",
       "1          7.11            1        0.67  \n",
       "2          5.94            1        1.19  \n",
       "3          5.85            1        2.18  \n",
       "4          5.82            1        0.93  \n",
       "..          ...          ...         ...  \n",
       "994        0.00            0        0.99  \n",
       "995        0.00            0        1.44  \n",
       "996        0.00            0        1.97  \n",
       "997        0.00            0        1.75  \n",
       "998        0.00            0        1.18  \n",
       "\n",
       "[999 rows x 10 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('SimLex-999/SimLex-999.txt', sep='\\t')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae8b84f",
   "metadata": {},
   "source": [
    "## 1. Word similarities based on WordNet's *path_similarity*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7cc6c5ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of pairs with missing words: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word1</th>\n",
       "      <th>word2</th>\n",
       "      <th>POS</th>\n",
       "      <th>SimLex999</th>\n",
       "      <th>conc(w1)</th>\n",
       "      <th>conc(w2)</th>\n",
       "      <th>concQ</th>\n",
       "      <th>Assoc(USF)</th>\n",
       "      <th>SimAssoc333</th>\n",
       "      <th>SD(SimLex)</th>\n",
       "      <th>WordNet path similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>old</td>\n",
       "      <td>new</td>\n",
       "      <td>A</td>\n",
       "      <td>1.58</td>\n",
       "      <td>2.72</td>\n",
       "      <td>2.81</td>\n",
       "      <td>2</td>\n",
       "      <td>7.25</td>\n",
       "      <td>1</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>smart</td>\n",
       "      <td>intelligent</td>\n",
       "      <td>A</td>\n",
       "      <td>9.20</td>\n",
       "      <td>1.75</td>\n",
       "      <td>2.46</td>\n",
       "      <td>1</td>\n",
       "      <td>7.11</td>\n",
       "      <td>1</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hard</td>\n",
       "      <td>difficult</td>\n",
       "      <td>A</td>\n",
       "      <td>8.77</td>\n",
       "      <td>3.76</td>\n",
       "      <td>2.21</td>\n",
       "      <td>2</td>\n",
       "      <td>5.94</td>\n",
       "      <td>1</td>\n",
       "      <td>1.19</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>happy</td>\n",
       "      <td>cheerful</td>\n",
       "      <td>A</td>\n",
       "      <td>9.55</td>\n",
       "      <td>2.56</td>\n",
       "      <td>2.34</td>\n",
       "      <td>1</td>\n",
       "      <td>5.85</td>\n",
       "      <td>1</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hard</td>\n",
       "      <td>easy</td>\n",
       "      <td>A</td>\n",
       "      <td>0.95</td>\n",
       "      <td>3.76</td>\n",
       "      <td>2.07</td>\n",
       "      <td>2</td>\n",
       "      <td>5.82</td>\n",
       "      <td>1</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>join</td>\n",
       "      <td>acquire</td>\n",
       "      <td>V</td>\n",
       "      <td>2.85</td>\n",
       "      <td>2.86</td>\n",
       "      <td>2.93</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>send</td>\n",
       "      <td>attend</td>\n",
       "      <td>V</td>\n",
       "      <td>1.67</td>\n",
       "      <td>2.70</td>\n",
       "      <td>3.17</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1.44</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>gather</td>\n",
       "      <td>attend</td>\n",
       "      <td>V</td>\n",
       "      <td>4.80</td>\n",
       "      <td>2.75</td>\n",
       "      <td>3.17</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1.97</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>absorb</td>\n",
       "      <td>withdraw</td>\n",
       "      <td>V</td>\n",
       "      <td>2.97</td>\n",
       "      <td>3.11</td>\n",
       "      <td>3.04</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1.75</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>attend</td>\n",
       "      <td>arrive</td>\n",
       "      <td>V</td>\n",
       "      <td>6.08</td>\n",
       "      <td>3.17</td>\n",
       "      <td>3.22</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1.18</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>999 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      word1        word2 POS  SimLex999  conc(w1)  conc(w2)  concQ  \\\n",
       "0       old          new   A       1.58      2.72      2.81      2   \n",
       "1     smart  intelligent   A       9.20      1.75      2.46      1   \n",
       "2      hard    difficult   A       8.77      3.76      2.21      2   \n",
       "3     happy     cheerful   A       9.55      2.56      2.34      1   \n",
       "4      hard         easy   A       0.95      3.76      2.07      2   \n",
       "..      ...          ...  ..        ...       ...       ...    ...   \n",
       "994    join      acquire   V       2.85      2.86      2.93      2   \n",
       "995    send       attend   V       1.67      2.70      3.17      2   \n",
       "996  gather       attend   V       4.80      2.75      3.17      2   \n",
       "997  absorb     withdraw   V       2.97      3.11      3.04      2   \n",
       "998  attend       arrive   V       6.08      3.17      3.22      2   \n",
       "\n",
       "     Assoc(USF)  SimAssoc333  SD(SimLex)  WordNet path similarity  \n",
       "0          7.25            1        0.41                 0.333333  \n",
       "1          7.11            1        0.67                 0.333333  \n",
       "2          5.94            1        1.19                 1.000000  \n",
       "3          5.85            1        2.18                 0.333333  \n",
       "4          5.82            1        0.93                 0.333333  \n",
       "..          ...          ...         ...                      ...  \n",
       "994        0.00            0        0.99                 0.333333  \n",
       "995        0.00            0        1.44                 0.200000  \n",
       "996        0.00            0        1.97                 0.250000  \n",
       "997        0.00            0        1.75                 0.333333  \n",
       "998        0.00            0        1.18                 0.250000  \n",
       "\n",
       "[999 rows x 11 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_sims = []\n",
    "missing_idxs = [] # for storing words missing in WordNet\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "    \n",
    "    # identifying the WordNet's POS\n",
    "    wn_pos = None\n",
    "    if row['POS'] == 'N':\n",
    "        wn_pos = wn.NOUN\n",
    "    elif row['POS'] == 'V':\n",
    "        wn_pos = wn.VERB\n",
    "    else:\n",
    "        wn_pos = wn.ADJ\n",
    "    \n",
    "    # extracting all synsets for word1 and word2 with the corresponding pos \n",
    "    word1_pos_synsets = [s for s in wn.synsets(row['word1'], pos=wn_pos)]\n",
    "    word2_pos_synsets = [s for s in wn.synsets(row['word2'], pos=wn_pos)]\n",
    "\n",
    "    # for storing instances with missing words\n",
    "    if min(len(word1_pos_synsets), len(word2_pos_synsets)) == 0:\n",
    "        missing_idxs.append(i)\n",
    "        path_sims.append(0)  # no such instances though\n",
    "        continue\n",
    "\n",
    "    # calculating path similarities for all combinations of synsets for the two words\n",
    "    all_comb_path_sims = []\n",
    "    for synset_w1 in word1_pos_synsets:\n",
    "        for synset_w2 in word2_pos_synsets:\n",
    "            all_comb_path_sims.append(wn.path_similarity(synset_w1, synset_w2))\n",
    "    path_sims.append(max(all_comb_path_sims))\n",
    "        \n",
    "        \n",
    "print('Number of pairs with missing words:', len(missing_idxs))\n",
    "\n",
    "df['WordNet path similarity'] = path_sims\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73426670",
   "metadata": {},
   "source": [
    "## 2. Word similarities based on FastText's word vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f81733b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "fasttext.util.download_model('en', if_exists='ignore')\n",
    "ft = fasttext.load_model('cc.en.300.bin')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae8c85ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of words in the vocabulary: 2000000\n",
      "Number of pairs with missing words: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word1</th>\n",
       "      <th>word2</th>\n",
       "      <th>POS</th>\n",
       "      <th>SimLex999</th>\n",
       "      <th>conc(w1)</th>\n",
       "      <th>conc(w2)</th>\n",
       "      <th>concQ</th>\n",
       "      <th>Assoc(USF)</th>\n",
       "      <th>SimAssoc333</th>\n",
       "      <th>SD(SimLex)</th>\n",
       "      <th>WordNet path similarity</th>\n",
       "      <th>FastText vectors similarity (cc.en.300)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>old</td>\n",
       "      <td>new</td>\n",
       "      <td>A</td>\n",
       "      <td>1.58</td>\n",
       "      <td>2.72</td>\n",
       "      <td>2.81</td>\n",
       "      <td>2</td>\n",
       "      <td>7.25</td>\n",
       "      <td>1</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.441964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>smart</td>\n",
       "      <td>intelligent</td>\n",
       "      <td>A</td>\n",
       "      <td>9.20</td>\n",
       "      <td>1.75</td>\n",
       "      <td>2.46</td>\n",
       "      <td>1</td>\n",
       "      <td>7.11</td>\n",
       "      <td>1</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.704955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hard</td>\n",
       "      <td>difficult</td>\n",
       "      <td>A</td>\n",
       "      <td>8.77</td>\n",
       "      <td>3.76</td>\n",
       "      <td>2.21</td>\n",
       "      <td>2</td>\n",
       "      <td>5.94</td>\n",
       "      <td>1</td>\n",
       "      <td>1.19</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.631380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>happy</td>\n",
       "      <td>cheerful</td>\n",
       "      <td>A</td>\n",
       "      <td>9.55</td>\n",
       "      <td>2.56</td>\n",
       "      <td>2.34</td>\n",
       "      <td>1</td>\n",
       "      <td>5.85</td>\n",
       "      <td>1</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.545871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hard</td>\n",
       "      <td>easy</td>\n",
       "      <td>A</td>\n",
       "      <td>0.95</td>\n",
       "      <td>3.76</td>\n",
       "      <td>2.07</td>\n",
       "      <td>2</td>\n",
       "      <td>5.82</td>\n",
       "      <td>1</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.486345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>join</td>\n",
       "      <td>acquire</td>\n",
       "      <td>V</td>\n",
       "      <td>2.85</td>\n",
       "      <td>2.86</td>\n",
       "      <td>2.93</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.229357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>send</td>\n",
       "      <td>attend</td>\n",
       "      <td>V</td>\n",
       "      <td>1.67</td>\n",
       "      <td>2.70</td>\n",
       "      <td>3.17</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1.44</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.350965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>gather</td>\n",
       "      <td>attend</td>\n",
       "      <td>V</td>\n",
       "      <td>4.80</td>\n",
       "      <td>2.75</td>\n",
       "      <td>3.17</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1.97</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.377495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>absorb</td>\n",
       "      <td>withdraw</td>\n",
       "      <td>V</td>\n",
       "      <td>2.97</td>\n",
       "      <td>3.11</td>\n",
       "      <td>3.04</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1.75</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.297315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>attend</td>\n",
       "      <td>arrive</td>\n",
       "      <td>V</td>\n",
       "      <td>6.08</td>\n",
       "      <td>3.17</td>\n",
       "      <td>3.22</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1.18</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.387084</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>999 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      word1        word2 POS  SimLex999  conc(w1)  conc(w2)  concQ  \\\n",
       "0       old          new   A       1.58      2.72      2.81      2   \n",
       "1     smart  intelligent   A       9.20      1.75      2.46      1   \n",
       "2      hard    difficult   A       8.77      3.76      2.21      2   \n",
       "3     happy     cheerful   A       9.55      2.56      2.34      1   \n",
       "4      hard         easy   A       0.95      3.76      2.07      2   \n",
       "..      ...          ...  ..        ...       ...       ...    ...   \n",
       "994    join      acquire   V       2.85      2.86      2.93      2   \n",
       "995    send       attend   V       1.67      2.70      3.17      2   \n",
       "996  gather       attend   V       4.80      2.75      3.17      2   \n",
       "997  absorb     withdraw   V       2.97      3.11      3.04      2   \n",
       "998  attend       arrive   V       6.08      3.17      3.22      2   \n",
       "\n",
       "     Assoc(USF)  SimAssoc333  SD(SimLex)  WordNet path similarity  \\\n",
       "0          7.25            1        0.41                 0.333333   \n",
       "1          7.11            1        0.67                 0.333333   \n",
       "2          5.94            1        1.19                 1.000000   \n",
       "3          5.85            1        2.18                 0.333333   \n",
       "4          5.82            1        0.93                 0.333333   \n",
       "..          ...          ...         ...                      ...   \n",
       "994        0.00            0        0.99                 0.333333   \n",
       "995        0.00            0        1.44                 0.200000   \n",
       "996        0.00            0        1.97                 0.250000   \n",
       "997        0.00            0        1.75                 0.333333   \n",
       "998        0.00            0        1.18                 0.250000   \n",
       "\n",
       "     FastText vectors similarity (cc.en.300)  \n",
       "0                                   0.441964  \n",
       "1                                   0.704955  \n",
       "2                                   0.631380  \n",
       "3                                   0.545871  \n",
       "4                                   0.486345  \n",
       "..                                       ...  \n",
       "994                                 0.229357  \n",
       "995                                 0.350965  \n",
       "996                                 0.377495  \n",
       "997                                 0.297315  \n",
       "998                                 0.387084  \n",
       "\n",
       "[999 rows x 12 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_sims = []\n",
    "missing_idxs = [] # for storing words missing in the model\n",
    "\n",
    "all_words = ft.get_words()\n",
    "print('Total number of words in the vocabulary:', len(all_words))\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "    \n",
    "    if (row['word1'] not in all_words) or (row['word2'] not in all_words):\n",
    "        missing_idxs.append(i) # remembering the idx of the pair\n",
    "        cos_sims.append(0)     # storing some arbitrary value\n",
    "        continue\n",
    "    else:\n",
    "        word1_vec = ft.get_word_vector(row['word1'])\n",
    "        word2_vec = ft.get_word_vector(row['word2'])\n",
    "        cos_sims.append(1 - cosine(word1_vec, word2_vec))  # actually, it is 1-(1-cos_sim)\n",
    "\n",
    "print('Number of pairs with missing words:', len(missing_idxs))\n",
    "\n",
    "df['FastText vectors similarity (cc.en.300)'] = cos_sims\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "965d78c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clear memory as the model holds ~7Gb of RAM\n",
    "del ft\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de1cd448",
   "metadata": {},
   "source": [
    "## 3. Word similarities based on WordNet's *wup_similarity*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06a32a2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of pairs with missing words: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word1</th>\n",
       "      <th>word2</th>\n",
       "      <th>POS</th>\n",
       "      <th>SimLex999</th>\n",
       "      <th>conc(w1)</th>\n",
       "      <th>conc(w2)</th>\n",
       "      <th>concQ</th>\n",
       "      <th>Assoc(USF)</th>\n",
       "      <th>SimAssoc333</th>\n",
       "      <th>SD(SimLex)</th>\n",
       "      <th>WordNet path similarity</th>\n",
       "      <th>FastText vectors similarity (cc.en.300)</th>\n",
       "      <th>WordNet WUP similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>old</td>\n",
       "      <td>new</td>\n",
       "      <td>A</td>\n",
       "      <td>1.58</td>\n",
       "      <td>2.72</td>\n",
       "      <td>2.81</td>\n",
       "      <td>2</td>\n",
       "      <td>7.25</td>\n",
       "      <td>1</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.441964</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>smart</td>\n",
       "      <td>intelligent</td>\n",
       "      <td>A</td>\n",
       "      <td>9.20</td>\n",
       "      <td>1.75</td>\n",
       "      <td>2.46</td>\n",
       "      <td>1</td>\n",
       "      <td>7.11</td>\n",
       "      <td>1</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.704955</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hard</td>\n",
       "      <td>difficult</td>\n",
       "      <td>A</td>\n",
       "      <td>8.77</td>\n",
       "      <td>3.76</td>\n",
       "      <td>2.21</td>\n",
       "      <td>2</td>\n",
       "      <td>5.94</td>\n",
       "      <td>1</td>\n",
       "      <td>1.19</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.631380</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>happy</td>\n",
       "      <td>cheerful</td>\n",
       "      <td>A</td>\n",
       "      <td>9.55</td>\n",
       "      <td>2.56</td>\n",
       "      <td>2.34</td>\n",
       "      <td>1</td>\n",
       "      <td>5.85</td>\n",
       "      <td>1</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.545871</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hard</td>\n",
       "      <td>easy</td>\n",
       "      <td>A</td>\n",
       "      <td>0.95</td>\n",
       "      <td>3.76</td>\n",
       "      <td>2.07</td>\n",
       "      <td>2</td>\n",
       "      <td>5.82</td>\n",
       "      <td>1</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.486345</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>join</td>\n",
       "      <td>acquire</td>\n",
       "      <td>V</td>\n",
       "      <td>2.85</td>\n",
       "      <td>2.86</td>\n",
       "      <td>2.93</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.229357</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>send</td>\n",
       "      <td>attend</td>\n",
       "      <td>V</td>\n",
       "      <td>1.67</td>\n",
       "      <td>2.70</td>\n",
       "      <td>3.17</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1.44</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.350965</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>gather</td>\n",
       "      <td>attend</td>\n",
       "      <td>V</td>\n",
       "      <td>4.80</td>\n",
       "      <td>2.75</td>\n",
       "      <td>3.17</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1.97</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.377495</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>absorb</td>\n",
       "      <td>withdraw</td>\n",
       "      <td>V</td>\n",
       "      <td>2.97</td>\n",
       "      <td>3.11</td>\n",
       "      <td>3.04</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1.75</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.297315</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>attend</td>\n",
       "      <td>arrive</td>\n",
       "      <td>V</td>\n",
       "      <td>6.08</td>\n",
       "      <td>3.17</td>\n",
       "      <td>3.22</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1.18</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.387084</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>999 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      word1        word2 POS  SimLex999  conc(w1)  conc(w2)  concQ  \\\n",
       "0       old          new   A       1.58      2.72      2.81      2   \n",
       "1     smart  intelligent   A       9.20      1.75      2.46      1   \n",
       "2      hard    difficult   A       8.77      3.76      2.21      2   \n",
       "3     happy     cheerful   A       9.55      2.56      2.34      1   \n",
       "4      hard         easy   A       0.95      3.76      2.07      2   \n",
       "..      ...          ...  ..        ...       ...       ...    ...   \n",
       "994    join      acquire   V       2.85      2.86      2.93      2   \n",
       "995    send       attend   V       1.67      2.70      3.17      2   \n",
       "996  gather       attend   V       4.80      2.75      3.17      2   \n",
       "997  absorb     withdraw   V       2.97      3.11      3.04      2   \n",
       "998  attend       arrive   V       6.08      3.17      3.22      2   \n",
       "\n",
       "     Assoc(USF)  SimAssoc333  SD(SimLex)  WordNet path similarity  \\\n",
       "0          7.25            1        0.41                 0.333333   \n",
       "1          7.11            1        0.67                 0.333333   \n",
       "2          5.94            1        1.19                 1.000000   \n",
       "3          5.85            1        2.18                 0.333333   \n",
       "4          5.82            1        0.93                 0.333333   \n",
       "..          ...          ...         ...                      ...   \n",
       "994        0.00            0        0.99                 0.333333   \n",
       "995        0.00            0        1.44                 0.200000   \n",
       "996        0.00            0        1.97                 0.250000   \n",
       "997        0.00            0        1.75                 0.333333   \n",
       "998        0.00            0        1.18                 0.250000   \n",
       "\n",
       "     FastText vectors similarity (cc.en.300)  WordNet WUP similarity  \n",
       "0                                   0.441964                0.500000  \n",
       "1                                   0.704955                0.500000  \n",
       "2                                   0.631380                1.000000  \n",
       "3                                   0.545871                0.500000  \n",
       "4                                   0.486345                0.500000  \n",
       "..                                       ...                     ...  \n",
       "994                                 0.229357                0.500000  \n",
       "995                                 0.350965                0.333333  \n",
       "996                                 0.377495                0.400000  \n",
       "997                                 0.297315                0.500000  \n",
       "998                                 0.387084                0.400000  \n",
       "\n",
       "[999 rows x 13 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wup_sims = []\n",
    "missing_idxs = [] # for storing words missing in WordNet\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "    \n",
    "    # identifying the WordNet's POS\n",
    "    wn_pos = None\n",
    "    if row['POS'] == 'N':\n",
    "        wn_pos = wn.NOUN\n",
    "    elif row['POS'] == 'V':\n",
    "        wn_pos = wn.VERB\n",
    "    else:\n",
    "        wn_pos = wn.ADJ\n",
    "    \n",
    "    # extracting all synsets for word1 and word2 with the corresponding pos \n",
    "    word1_pos_synsets = [s for s in wn.synsets(row['word1'], pos=wn_pos)]\n",
    "    word2_pos_synsets = [s for s in wn.synsets(row['word2'], pos=wn_pos)]\n",
    "\n",
    "    # for storing instances with missing words\n",
    "    if min(len(word1_pos_synsets), len(word2_pos_synsets)) == 0:\n",
    "        missing_idxs.append(i)\n",
    "        wup_sims.append(0)  # no such instances though\n",
    "        continue\n",
    "\n",
    "    # calculating wup similarities for all combinations of synsets for the two words\n",
    "    all_comb_wup_sims = []\n",
    "    for synset_w1 in word1_pos_synsets:\n",
    "        for synset_w2 in word2_pos_synsets:\n",
    "            all_comb_wup_sims.append(wn.wup_similarity(synset_w1, synset_w2))\n",
    "    wup_sims.append(max(all_comb_wup_sims))\n",
    "        \n",
    "        \n",
    "print('Number of pairs with missing words:', len(missing_idxs))\n",
    "\n",
    "df['WordNet WUP similarity'] = wup_sims\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c662d204",
   "metadata": {},
   "source": [
    "## 4. Word similarities based on fastText's word vectors, other models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a37e0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# method from the FastText website\n",
    "# explodes size of the dictionary, leading to program crash (lack of memory)\n",
    "\n",
    "# def load_vectors(fname):\n",
    "#     fin = io.open(fname, 'r', encoding='utf-8', newline='\\n', errors='ignore')\n",
    "#     n, d = map(int, fin.readline().split())\n",
    "#     data = {}\n",
    "#     for line in fin:\n",
    "#         tokens = line.rstrip().split(' ')\n",
    "#         data[tokens[0]] = map(float, tokens[1:])\n",
    "#     return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a4157327",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'crawl-300d-2M.vec'\n",
    "ft_vecs = KeyedVectors.load_word2vec_format(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f5560ecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of words in the vocabulary: 1999995\n",
      "Number of pairs with missing words: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word1</th>\n",
       "      <th>word2</th>\n",
       "      <th>POS</th>\n",
       "      <th>SimLex999</th>\n",
       "      <th>conc(w1)</th>\n",
       "      <th>conc(w2)</th>\n",
       "      <th>concQ</th>\n",
       "      <th>Assoc(USF)</th>\n",
       "      <th>SimAssoc333</th>\n",
       "      <th>SD(SimLex)</th>\n",
       "      <th>WordNet path similarity</th>\n",
       "      <th>FastText vectors similarity (cc.en.300)</th>\n",
       "      <th>WordNet WUP similarity</th>\n",
       "      <th>FastText vectors similarity (crawl-300d-2M)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>old</td>\n",
       "      <td>new</td>\n",
       "      <td>A</td>\n",
       "      <td>1.58</td>\n",
       "      <td>2.72</td>\n",
       "      <td>2.81</td>\n",
       "      <td>2</td>\n",
       "      <td>7.25</td>\n",
       "      <td>1</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.441964</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.504730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>smart</td>\n",
       "      <td>intelligent</td>\n",
       "      <td>A</td>\n",
       "      <td>9.20</td>\n",
       "      <td>1.75</td>\n",
       "      <td>2.46</td>\n",
       "      <td>1</td>\n",
       "      <td>7.11</td>\n",
       "      <td>1</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.704955</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.780194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hard</td>\n",
       "      <td>difficult</td>\n",
       "      <td>A</td>\n",
       "      <td>8.77</td>\n",
       "      <td>3.76</td>\n",
       "      <td>2.21</td>\n",
       "      <td>2</td>\n",
       "      <td>5.94</td>\n",
       "      <td>1</td>\n",
       "      <td>1.19</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.631380</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.771711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>happy</td>\n",
       "      <td>cheerful</td>\n",
       "      <td>A</td>\n",
       "      <td>9.55</td>\n",
       "      <td>2.56</td>\n",
       "      <td>2.34</td>\n",
       "      <td>1</td>\n",
       "      <td>5.85</td>\n",
       "      <td>1</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.545871</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.554318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hard</td>\n",
       "      <td>easy</td>\n",
       "      <td>A</td>\n",
       "      <td>0.95</td>\n",
       "      <td>3.76</td>\n",
       "      <td>2.07</td>\n",
       "      <td>2</td>\n",
       "      <td>5.82</td>\n",
       "      <td>1</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.486345</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.589305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>join</td>\n",
       "      <td>acquire</td>\n",
       "      <td>V</td>\n",
       "      <td>2.85</td>\n",
       "      <td>2.86</td>\n",
       "      <td>2.93</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.229357</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.263337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>send</td>\n",
       "      <td>attend</td>\n",
       "      <td>V</td>\n",
       "      <td>1.67</td>\n",
       "      <td>2.70</td>\n",
       "      <td>3.17</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1.44</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.350965</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.359698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>gather</td>\n",
       "      <td>attend</td>\n",
       "      <td>V</td>\n",
       "      <td>4.80</td>\n",
       "      <td>2.75</td>\n",
       "      <td>3.17</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1.97</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.377495</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.375723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>absorb</td>\n",
       "      <td>withdraw</td>\n",
       "      <td>V</td>\n",
       "      <td>2.97</td>\n",
       "      <td>3.11</td>\n",
       "      <td>3.04</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1.75</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.297315</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.321654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>attend</td>\n",
       "      <td>arrive</td>\n",
       "      <td>V</td>\n",
       "      <td>6.08</td>\n",
       "      <td>3.17</td>\n",
       "      <td>3.22</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1.18</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.387084</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.352670</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>999 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      word1        word2 POS  SimLex999  conc(w1)  conc(w2)  concQ  \\\n",
       "0       old          new   A       1.58      2.72      2.81      2   \n",
       "1     smart  intelligent   A       9.20      1.75      2.46      1   \n",
       "2      hard    difficult   A       8.77      3.76      2.21      2   \n",
       "3     happy     cheerful   A       9.55      2.56      2.34      1   \n",
       "4      hard         easy   A       0.95      3.76      2.07      2   \n",
       "..      ...          ...  ..        ...       ...       ...    ...   \n",
       "994    join      acquire   V       2.85      2.86      2.93      2   \n",
       "995    send       attend   V       1.67      2.70      3.17      2   \n",
       "996  gather       attend   V       4.80      2.75      3.17      2   \n",
       "997  absorb     withdraw   V       2.97      3.11      3.04      2   \n",
       "998  attend       arrive   V       6.08      3.17      3.22      2   \n",
       "\n",
       "     Assoc(USF)  SimAssoc333  SD(SimLex)  WordNet path similarity  \\\n",
       "0          7.25            1        0.41                 0.333333   \n",
       "1          7.11            1        0.67                 0.333333   \n",
       "2          5.94            1        1.19                 1.000000   \n",
       "3          5.85            1        2.18                 0.333333   \n",
       "4          5.82            1        0.93                 0.333333   \n",
       "..          ...          ...         ...                      ...   \n",
       "994        0.00            0        0.99                 0.333333   \n",
       "995        0.00            0        1.44                 0.200000   \n",
       "996        0.00            0        1.97                 0.250000   \n",
       "997        0.00            0        1.75                 0.333333   \n",
       "998        0.00            0        1.18                 0.250000   \n",
       "\n",
       "     FastText vectors similarity (cc.en.300)  WordNet WUP similarity  \\\n",
       "0                                   0.441964                0.500000   \n",
       "1                                   0.704955                0.500000   \n",
       "2                                   0.631380                1.000000   \n",
       "3                                   0.545871                0.500000   \n",
       "4                                   0.486345                0.500000   \n",
       "..                                       ...                     ...   \n",
       "994                                 0.229357                0.500000   \n",
       "995                                 0.350965                0.333333   \n",
       "996                                 0.377495                0.400000   \n",
       "997                                 0.297315                0.500000   \n",
       "998                                 0.387084                0.400000   \n",
       "\n",
       "     FastText vectors similarity (crawl-300d-2M)  \n",
       "0                                       0.504730  \n",
       "1                                       0.780194  \n",
       "2                                       0.771711  \n",
       "3                                       0.554318  \n",
       "4                                       0.589305  \n",
       "..                                           ...  \n",
       "994                                     0.263337  \n",
       "995                                     0.359698  \n",
       "996                                     0.375723  \n",
       "997                                     0.321654  \n",
       "998                                     0.352670  \n",
       "\n",
       "[999 rows x 14 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_sims = []\n",
    "missing_idxs = []\n",
    "\n",
    "print('Total number of words in the vocabulary:', len(ft_vecs))\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "    \n",
    "    # obtaining word1 embedding, if exists\n",
    "    if row['word1'] in ft_vecs.key_to_index:\n",
    "        word1_vec = ft_vecs[row['word1']]\n",
    "    else:\n",
    "        missing_idxs.append(i)\n",
    "        continue\n",
    "      \n",
    "    # getting word2 embedding, if exists\n",
    "    if row['word2'] in ft_vecs.key_to_index:\n",
    "        word2_vec = ft_vecs[row['word2']]\n",
    "    else:\n",
    "        missing_idxs.append(i)\n",
    "        continue\n",
    "        \n",
    "    cos_sims.append(1-cosine(word1_vec, word2_vec))\n",
    "\n",
    "\n",
    "print('Number of pairs with missing words:', len(missing_idxs))\n",
    "\n",
    "df[f'FastText vectors similarity ({model.replace(\".vec\",\"\")})'] = cos_sims\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5ad15bd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del ft_vecs\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b9fbb25",
   "metadata": {},
   "source": [
    "## 6. Calculating Kendall's tau between the gold standard and obtained scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7c9edf15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimLex999 & WordNet path similarity: 0.3534\n"
     ]
    }
   ],
   "source": [
    "print(f\"SimLex999 & WordNet path similarity: {kendalltau(df['SimLex999'], df['WordNet path similarity']).statistic:.4}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5935e28d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimLex999 & FastText Word Vectors Similarity (cc.en.300): 0.3301\n"
     ]
    }
   ],
   "source": [
    "print(f\"SimLex999 & FastText Word Vectors Similarity (cc.en.300): {kendalltau(df['SimLex999'], df['FastText vectors similarity (cc.en.300)']).statistic:.4}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "47fefca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimLex999 & WordNet WUP similarity: 0.3211\n"
     ]
    }
   ],
   "source": [
    "print(f\"SimLex999 & WordNet WUP similarity: {kendalltau(df['SimLex999'], df['WordNet WUP similarity']).statistic:.4}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e492d287",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimLex999 & FastText Word Vectors Similarity (crawl-300d-2M): 0.3621\n"
     ]
    }
   ],
   "source": [
    "print(f\"SimLex999 & FastText Word Vectors Similarity (crawl-300d-2M): {kendalltau(df['SimLex999'], df['FastText vectors similarity (crawl-300d-2M)']).statistic:.4}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762a417e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "700e174d",
   "metadata": {},
   "source": [
    "## 7. Additional experimentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6c14fe18",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'crawl-300d-2M-subword.vec'\n",
    "ft_vecs = KeyedVectors.load_word2vec_format(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d2220f8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of words in the vocabulary: 2000000\n",
      "Number of pairs with missing words: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word1</th>\n",
       "      <th>word2</th>\n",
       "      <th>POS</th>\n",
       "      <th>SimLex999</th>\n",
       "      <th>conc(w1)</th>\n",
       "      <th>conc(w2)</th>\n",
       "      <th>concQ</th>\n",
       "      <th>Assoc(USF)</th>\n",
       "      <th>SimAssoc333</th>\n",
       "      <th>SD(SimLex)</th>\n",
       "      <th>WordNet path similarity</th>\n",
       "      <th>FastText vectors similarity (cc.en.300)</th>\n",
       "      <th>WordNet WUP similarity</th>\n",
       "      <th>FastText vectors similarity (crawl-300d-2M)</th>\n",
       "      <th>FastText vectors similarity (crawl-300d-2M-subword)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>old</td>\n",
       "      <td>new</td>\n",
       "      <td>A</td>\n",
       "      <td>1.58</td>\n",
       "      <td>2.72</td>\n",
       "      <td>2.81</td>\n",
       "      <td>2</td>\n",
       "      <td>7.25</td>\n",
       "      <td>1</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.441964</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.504730</td>\n",
       "      <td>0.654177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>smart</td>\n",
       "      <td>intelligent</td>\n",
       "      <td>A</td>\n",
       "      <td>9.20</td>\n",
       "      <td>1.75</td>\n",
       "      <td>2.46</td>\n",
       "      <td>1</td>\n",
       "      <td>7.11</td>\n",
       "      <td>1</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.704955</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.780194</td>\n",
       "      <td>0.795616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hard</td>\n",
       "      <td>difficult</td>\n",
       "      <td>A</td>\n",
       "      <td>8.77</td>\n",
       "      <td>3.76</td>\n",
       "      <td>2.21</td>\n",
       "      <td>2</td>\n",
       "      <td>5.94</td>\n",
       "      <td>1</td>\n",
       "      <td>1.19</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.631380</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.771711</td>\n",
       "      <td>0.836774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>happy</td>\n",
       "      <td>cheerful</td>\n",
       "      <td>A</td>\n",
       "      <td>9.55</td>\n",
       "      <td>2.56</td>\n",
       "      <td>2.34</td>\n",
       "      <td>1</td>\n",
       "      <td>5.85</td>\n",
       "      <td>1</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.545871</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.554318</td>\n",
       "      <td>0.648004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hard</td>\n",
       "      <td>easy</td>\n",
       "      <td>A</td>\n",
       "      <td>0.95</td>\n",
       "      <td>3.76</td>\n",
       "      <td>2.07</td>\n",
       "      <td>2</td>\n",
       "      <td>5.82</td>\n",
       "      <td>1</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.486345</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.589305</td>\n",
       "      <td>0.703270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>join</td>\n",
       "      <td>acquire</td>\n",
       "      <td>V</td>\n",
       "      <td>2.85</td>\n",
       "      <td>2.86</td>\n",
       "      <td>2.93</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.229357</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.263337</td>\n",
       "      <td>0.422737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>send</td>\n",
       "      <td>attend</td>\n",
       "      <td>V</td>\n",
       "      <td>1.67</td>\n",
       "      <td>2.70</td>\n",
       "      <td>3.17</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1.44</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.350965</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.359698</td>\n",
       "      <td>0.470447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>gather</td>\n",
       "      <td>attend</td>\n",
       "      <td>V</td>\n",
       "      <td>4.80</td>\n",
       "      <td>2.75</td>\n",
       "      <td>3.17</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1.97</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.377495</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.375723</td>\n",
       "      <td>0.491910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>absorb</td>\n",
       "      <td>withdraw</td>\n",
       "      <td>V</td>\n",
       "      <td>2.97</td>\n",
       "      <td>3.11</td>\n",
       "      <td>3.04</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1.75</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.297315</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.321654</td>\n",
       "      <td>0.481629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>attend</td>\n",
       "      <td>arrive</td>\n",
       "      <td>V</td>\n",
       "      <td>6.08</td>\n",
       "      <td>3.17</td>\n",
       "      <td>3.22</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1.18</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.387084</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.352670</td>\n",
       "      <td>0.525029</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>999 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      word1        word2 POS  SimLex999  conc(w1)  conc(w2)  concQ  \\\n",
       "0       old          new   A       1.58      2.72      2.81      2   \n",
       "1     smart  intelligent   A       9.20      1.75      2.46      1   \n",
       "2      hard    difficult   A       8.77      3.76      2.21      2   \n",
       "3     happy     cheerful   A       9.55      2.56      2.34      1   \n",
       "4      hard         easy   A       0.95      3.76      2.07      2   \n",
       "..      ...          ...  ..        ...       ...       ...    ...   \n",
       "994    join      acquire   V       2.85      2.86      2.93      2   \n",
       "995    send       attend   V       1.67      2.70      3.17      2   \n",
       "996  gather       attend   V       4.80      2.75      3.17      2   \n",
       "997  absorb     withdraw   V       2.97      3.11      3.04      2   \n",
       "998  attend       arrive   V       6.08      3.17      3.22      2   \n",
       "\n",
       "     Assoc(USF)  SimAssoc333  SD(SimLex)  WordNet path similarity  \\\n",
       "0          7.25            1        0.41                 0.333333   \n",
       "1          7.11            1        0.67                 0.333333   \n",
       "2          5.94            1        1.19                 1.000000   \n",
       "3          5.85            1        2.18                 0.333333   \n",
       "4          5.82            1        0.93                 0.333333   \n",
       "..          ...          ...         ...                      ...   \n",
       "994        0.00            0        0.99                 0.333333   \n",
       "995        0.00            0        1.44                 0.200000   \n",
       "996        0.00            0        1.97                 0.250000   \n",
       "997        0.00            0        1.75                 0.333333   \n",
       "998        0.00            0        1.18                 0.250000   \n",
       "\n",
       "     FastText vectors similarity (cc.en.300)  WordNet WUP similarity  \\\n",
       "0                                   0.441964                0.500000   \n",
       "1                                   0.704955                0.500000   \n",
       "2                                   0.631380                1.000000   \n",
       "3                                   0.545871                0.500000   \n",
       "4                                   0.486345                0.500000   \n",
       "..                                       ...                     ...   \n",
       "994                                 0.229357                0.500000   \n",
       "995                                 0.350965                0.333333   \n",
       "996                                 0.377495                0.400000   \n",
       "997                                 0.297315                0.500000   \n",
       "998                                 0.387084                0.400000   \n",
       "\n",
       "     FastText vectors similarity (crawl-300d-2M)  \\\n",
       "0                                       0.504730   \n",
       "1                                       0.780194   \n",
       "2                                       0.771711   \n",
       "3                                       0.554318   \n",
       "4                                       0.589305   \n",
       "..                                           ...   \n",
       "994                                     0.263337   \n",
       "995                                     0.359698   \n",
       "996                                     0.375723   \n",
       "997                                     0.321654   \n",
       "998                                     0.352670   \n",
       "\n",
       "     FastText vectors similarity (crawl-300d-2M-subword)  \n",
       "0                                             0.654177    \n",
       "1                                             0.795616    \n",
       "2                                             0.836774    \n",
       "3                                             0.648004    \n",
       "4                                             0.703270    \n",
       "..                                                 ...    \n",
       "994                                           0.422737    \n",
       "995                                           0.470447    \n",
       "996                                           0.491910    \n",
       "997                                           0.481629    \n",
       "998                                           0.525029    \n",
       "\n",
       "[999 rows x 15 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_sims = []\n",
    "missing_idxs = []\n",
    "\n",
    "print('Total number of words in the vocabulary:', len(ft_vecs))\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "    \n",
    "    # obtaining word1 embedding, if exists\n",
    "    if row['word1'] in ft_vecs.key_to_index:\n",
    "        word1_vec = ft_vecs[row['word1']]\n",
    "    else:\n",
    "        missing_idxs.append(i)\n",
    "        continue\n",
    "      \n",
    "    # getting word2 embedding, if exists\n",
    "    if row['word2'] in ft_vecs.key_to_index:\n",
    "        word2_vec = ft_vecs[row['word2']]\n",
    "    else:\n",
    "        missing_idxs.append(i)\n",
    "        continue\n",
    "        \n",
    "    cos_sims.append(1-cosine(word1_vec, word2_vec))\n",
    "\n",
    "\n",
    "print('Number of pairs with missing words:', len(missing_idxs))\n",
    "\n",
    "df[f'FastText vectors similarity ({model.replace(\".vec\",\"\")})'] = cos_sims\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f44b4a5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimLex999 & FastText Word Vectors Similarity (crawl-300d-2M-subword): 0.338\n"
     ]
    }
   ],
   "source": [
    "print(f\"SimLex999 & FastText Word Vectors Similarity (crawl-300d-2M-subword): {kendalltau(df['SimLex999'], df[f'FastText vectors similarity (crawl-300d-2M-subword)']).statistic:.4}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d58c602f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del ft_vecs\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc03d45f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76616304",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "30419d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'wiki-news-300d-1M.vec'\n",
    "ft_vecs = KeyedVectors.load_word2vec_format(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "233a4829",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of words in the vocabulary: 999994\n",
      "Number of pairs with missing words: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word1</th>\n",
       "      <th>word2</th>\n",
       "      <th>POS</th>\n",
       "      <th>SimLex999</th>\n",
       "      <th>conc(w1)</th>\n",
       "      <th>conc(w2)</th>\n",
       "      <th>concQ</th>\n",
       "      <th>Assoc(USF)</th>\n",
       "      <th>SimAssoc333</th>\n",
       "      <th>SD(SimLex)</th>\n",
       "      <th>WordNet path similarity</th>\n",
       "      <th>FastText vectors similarity (cc.en.300)</th>\n",
       "      <th>WordNet WUP similarity</th>\n",
       "      <th>FastText vectors similarity (crawl-300d-2M)</th>\n",
       "      <th>FastText vectors similarity (crawl-300d-2M-subword)</th>\n",
       "      <th>FastText vectors similarity (wiki-news-300d-1M)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>old</td>\n",
       "      <td>new</td>\n",
       "      <td>A</td>\n",
       "      <td>1.58</td>\n",
       "      <td>2.72</td>\n",
       "      <td>2.81</td>\n",
       "      <td>2</td>\n",
       "      <td>7.25</td>\n",
       "      <td>1</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.441964</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.504730</td>\n",
       "      <td>0.654177</td>\n",
       "      <td>0.653033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>smart</td>\n",
       "      <td>intelligent</td>\n",
       "      <td>A</td>\n",
       "      <td>9.20</td>\n",
       "      <td>1.75</td>\n",
       "      <td>2.46</td>\n",
       "      <td>1</td>\n",
       "      <td>7.11</td>\n",
       "      <td>1</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.704955</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.780194</td>\n",
       "      <td>0.795616</td>\n",
       "      <td>0.768561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hard</td>\n",
       "      <td>difficult</td>\n",
       "      <td>A</td>\n",
       "      <td>8.77</td>\n",
       "      <td>3.76</td>\n",
       "      <td>2.21</td>\n",
       "      <td>2</td>\n",
       "      <td>5.94</td>\n",
       "      <td>1</td>\n",
       "      <td>1.19</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.631380</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.771711</td>\n",
       "      <td>0.836774</td>\n",
       "      <td>0.701083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>happy</td>\n",
       "      <td>cheerful</td>\n",
       "      <td>A</td>\n",
       "      <td>9.55</td>\n",
       "      <td>2.56</td>\n",
       "      <td>2.34</td>\n",
       "      <td>1</td>\n",
       "      <td>5.85</td>\n",
       "      <td>1</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.545871</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.554318</td>\n",
       "      <td>0.648004</td>\n",
       "      <td>0.663085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hard</td>\n",
       "      <td>easy</td>\n",
       "      <td>A</td>\n",
       "      <td>0.95</td>\n",
       "      <td>3.76</td>\n",
       "      <td>2.07</td>\n",
       "      <td>2</td>\n",
       "      <td>5.82</td>\n",
       "      <td>1</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.486345</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.589305</td>\n",
       "      <td>0.703270</td>\n",
       "      <td>0.645981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>join</td>\n",
       "      <td>acquire</td>\n",
       "      <td>V</td>\n",
       "      <td>2.85</td>\n",
       "      <td>2.86</td>\n",
       "      <td>2.93</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.229357</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.263337</td>\n",
       "      <td>0.422737</td>\n",
       "      <td>0.542489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>send</td>\n",
       "      <td>attend</td>\n",
       "      <td>V</td>\n",
       "      <td>1.67</td>\n",
       "      <td>2.70</td>\n",
       "      <td>3.17</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1.44</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.350965</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.359698</td>\n",
       "      <td>0.470447</td>\n",
       "      <td>0.587319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>gather</td>\n",
       "      <td>attend</td>\n",
       "      <td>V</td>\n",
       "      <td>4.80</td>\n",
       "      <td>2.75</td>\n",
       "      <td>3.17</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1.97</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.377495</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.375723</td>\n",
       "      <td>0.491910</td>\n",
       "      <td>0.587173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>absorb</td>\n",
       "      <td>withdraw</td>\n",
       "      <td>V</td>\n",
       "      <td>2.97</td>\n",
       "      <td>3.11</td>\n",
       "      <td>3.04</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1.75</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.297315</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.321654</td>\n",
       "      <td>0.481629</td>\n",
       "      <td>0.463984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>attend</td>\n",
       "      <td>arrive</td>\n",
       "      <td>V</td>\n",
       "      <td>6.08</td>\n",
       "      <td>3.17</td>\n",
       "      <td>3.22</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1.18</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.387084</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.352670</td>\n",
       "      <td>0.525029</td>\n",
       "      <td>0.560066</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>999 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      word1        word2 POS  SimLex999  conc(w1)  conc(w2)  concQ  \\\n",
       "0       old          new   A       1.58      2.72      2.81      2   \n",
       "1     smart  intelligent   A       9.20      1.75      2.46      1   \n",
       "2      hard    difficult   A       8.77      3.76      2.21      2   \n",
       "3     happy     cheerful   A       9.55      2.56      2.34      1   \n",
       "4      hard         easy   A       0.95      3.76      2.07      2   \n",
       "..      ...          ...  ..        ...       ...       ...    ...   \n",
       "994    join      acquire   V       2.85      2.86      2.93      2   \n",
       "995    send       attend   V       1.67      2.70      3.17      2   \n",
       "996  gather       attend   V       4.80      2.75      3.17      2   \n",
       "997  absorb     withdraw   V       2.97      3.11      3.04      2   \n",
       "998  attend       arrive   V       6.08      3.17      3.22      2   \n",
       "\n",
       "     Assoc(USF)  SimAssoc333  SD(SimLex)  WordNet path similarity  \\\n",
       "0          7.25            1        0.41                 0.333333   \n",
       "1          7.11            1        0.67                 0.333333   \n",
       "2          5.94            1        1.19                 1.000000   \n",
       "3          5.85            1        2.18                 0.333333   \n",
       "4          5.82            1        0.93                 0.333333   \n",
       "..          ...          ...         ...                      ...   \n",
       "994        0.00            0        0.99                 0.333333   \n",
       "995        0.00            0        1.44                 0.200000   \n",
       "996        0.00            0        1.97                 0.250000   \n",
       "997        0.00            0        1.75                 0.333333   \n",
       "998        0.00            0        1.18                 0.250000   \n",
       "\n",
       "     FastText vectors similarity (cc.en.300)  WordNet WUP similarity  \\\n",
       "0                                   0.441964                0.500000   \n",
       "1                                   0.704955                0.500000   \n",
       "2                                   0.631380                1.000000   \n",
       "3                                   0.545871                0.500000   \n",
       "4                                   0.486345                0.500000   \n",
       "..                                       ...                     ...   \n",
       "994                                 0.229357                0.500000   \n",
       "995                                 0.350965                0.333333   \n",
       "996                                 0.377495                0.400000   \n",
       "997                                 0.297315                0.500000   \n",
       "998                                 0.387084                0.400000   \n",
       "\n",
       "     FastText vectors similarity (crawl-300d-2M)  \\\n",
       "0                                       0.504730   \n",
       "1                                       0.780194   \n",
       "2                                       0.771711   \n",
       "3                                       0.554318   \n",
       "4                                       0.589305   \n",
       "..                                           ...   \n",
       "994                                     0.263337   \n",
       "995                                     0.359698   \n",
       "996                                     0.375723   \n",
       "997                                     0.321654   \n",
       "998                                     0.352670   \n",
       "\n",
       "     FastText vectors similarity (crawl-300d-2M-subword)  \\\n",
       "0                                             0.654177     \n",
       "1                                             0.795616     \n",
       "2                                             0.836774     \n",
       "3                                             0.648004     \n",
       "4                                             0.703270     \n",
       "..                                                 ...     \n",
       "994                                           0.422737     \n",
       "995                                           0.470447     \n",
       "996                                           0.491910     \n",
       "997                                           0.481629     \n",
       "998                                           0.525029     \n",
       "\n",
       "     FastText vectors similarity (wiki-news-300d-1M)  \n",
       "0                                           0.653033  \n",
       "1                                           0.768561  \n",
       "2                                           0.701083  \n",
       "3                                           0.663085  \n",
       "4                                           0.645981  \n",
       "..                                               ...  \n",
       "994                                         0.542489  \n",
       "995                                         0.587319  \n",
       "996                                         0.587173  \n",
       "997                                         0.463984  \n",
       "998                                         0.560066  \n",
       "\n",
       "[999 rows x 16 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_sims = []\n",
    "missing_idxs = []\n",
    "\n",
    "print('Total number of words in the vocabulary:', len(ft_vecs))\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "    \n",
    "    # obtaining word1 embedding, if exists\n",
    "    if row['word1'] in ft_vecs.key_to_index:\n",
    "        word1_vec = ft_vecs[row['word1']]\n",
    "    else:\n",
    "        missing_idxs.append(i)\n",
    "        continue\n",
    "      \n",
    "    # getting word2 embedding, if exists\n",
    "    if row['word2'] in ft_vecs.key_to_index:\n",
    "        word2_vec = ft_vecs[row['word2']]\n",
    "    else:\n",
    "        missing_idxs.append(i)\n",
    "        continue\n",
    "        \n",
    "    cos_sims.append(1-cosine(word1_vec, word2_vec))\n",
    "\n",
    "\n",
    "print('Number of pairs with missing words:', len(missing_idxs))\n",
    "\n",
    "df[f'FastText vectors similarity ({model.replace(\".vec\",\"\")})'] = cos_sims\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7c64af80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimLex999 & FastText Word Vectors Similarity (wiki-news-300d-1M): 0.3223\n"
     ]
    }
   ],
   "source": [
    "print(f\"SimLex999 & FastText Word Vectors Similarity (wiki-news-300d-1M): {kendalltau(df['SimLex999'], df[f'FastText vectors similarity (wiki-news-300d-1M)']).statistic:.4}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6cdbba3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178e1be3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dabb5c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
